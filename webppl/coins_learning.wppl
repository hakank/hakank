/*

  From srl-pp-tutorial-wasp-stockholm.pdf
  "Statistical Relational learning and Probabilistic Programming"
  by Luc De Raedt, Anton Dries, and Angelika Kimmig
  https://dtai.cs.kuleuven.be/problog/wasp17-tutorial.html
  
  slide 394f:
  """
  - Flipping a coin with unknown weight
  - Prior: uniform distribution on [0,1]
  - Observation: 5x heads in a row
  """

  The ProbLog model return the following which corresponds to the
  density of the probabilist 
  """
   weight(c1,0.1): 3.3994697e-13
   weight(c1,0.3): 2.1679411e-06
   weight(c1,0.5): 0.0041497433
   weight(c1,0.7): 0.1317485 
   weight(c1,0.9): 0.86409959         <----
   weight(c2,0.1): 3.2276726e-06
   weight(c2,0.3): 0.024109997
   weight(c2,0.5): 0.66724754         <----
   weight(c2,0.7): 0.30628626
   weight(c2,0.9): 0.0023529733
  """

  Here we observe 13 tosses and detecting the probability of throwing a head.

  Cf ~/problog/coins_learning.pl
     ~/blog/coins_learning.blog

  Note that this model is much simpler than the ProbLog model since ProbLog 
  don't support continous distributions. 
  Which makes it clear that I might have missed the point of the ProbLog model. :-)
  
  For a model which is much more close to the ProbLog model, see coins_learning2.wppl.

*/

var model = function() {

    // var p = beta(2,2);
    var p = uniform(0,1);    
    var data = function(i) {
        return flip(p);
    }

    // p: expectation 0.9277183539318042
    /*
    condition(data(0) == true);
    condition(data(1) == true);
    condition(data(2) == true);
    condition(data(3) == true);
    condition(data(4) == true);
    condition(data(5) == true);
    condition(data(6) == true);
    condition(data(7) == true);
    condition(data(8) == true);
    condition(data(9) == true);
    condition(data(10) == true);
    condition(data(11) == true);
    condition(data(12) == true);
    */


    // p: expectation 0.6568830353077122
    condition(data(0) == true);
    condition(data(1) == false);
    condition(data(2) == true); 
    condition(data(3) == true);
    condition(data(4) == true);
    condition(data(5) == true);
    condition(data(6) == true); 
    condition(data(7) == false);
    condition(data(8) == false);
    condition(data(9) == true); 
    condition(data(10) == false);
    condition(data(11) == false);
    condition(data(12) == true);


    return {
        p:p,
        data0:data(0) == true,
        data1:data(1) == true,
        data2:data(2) == true,
        data3:data(3) == true,
        data4:data(4) == true,
        data5:data(5) == true,
        data6:data(6) == true,
        data7:data(7) == true,
        data8:data(8) == true,
        data9:data(9) == true,
        data10:data(10) == true,
        data11:data(11) == true,
        data12:data(12) == true,

    }

}

// var d = Infer({method:"rejection",samples:1000},model);
var d = Infer({method:"MCMC",kernel:"MH",samples:10000},model);
display(d);

var exp_map = function(d,arr) {
    display("Marginals:");
    map(function(a) {display(a);display(marginalize(d, a)) }, arr);
    display("expectation:");
    display(map(function(a) { [a,expectation(marginalize(d, a))] }, arr));
    // display("MAP:");
    // display(map(function(a) { [a,MAP(marginalize(d, a))] }, arr));
}

exp_map(d,["p",
           "data0","data1","data2","data3",
           "data4","data5","data6","data7",
           "data8","data9","data10","data11",
           "data12",
          ]);
