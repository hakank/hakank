/*
  Coupon collector problem.

  From https://www.maa.org/frank-morgans-math-chat-rolling-a-die-until-every-face-has-appeared
  """
  LD CHALLENGE (Steve Jabloner). How many times do you think you need to roll a
  normal die to be 90% sure that each of the six faces has appeared at least once? Why?

  ANSWER. It takes 23 rolls, as Al Zimmerman discovered in a computer experiment 
  rolling 5000 dice until 90% of them had shown each face. In a less accurate 
  experiment with just 300 dice, Eric Brahinsky wrongly concluded that 22 rolls 
  provide a 90.7% probability. 
  """

  For a collection of 6 different cards:

  len
  Marginal:
    10 : 0.09150000000000001
    13 : 0.08650000000000001
    12 : 0.08399999999999999
    11 : 0.07900000000000001
    14 : 0.06949999999999999
    9 : 0.0645
    15 : 0.0595
    8 : 0.057500000000000016
    16 : 0.05449999999999999
    18 : 0.0465

  expectation:
  [ [ 'len', 14.678 ] ]

  Credible interval for len (94%): [ 6, 26 ]

  var len
  min: 6
  listMean: 14.678
  listVar: 41.40631600000067
  listStdev: 6.434773966504237
  max: 80
  Percentiles:
  [ [ 0, 6 ],
    [ 2.5, 7 ],
    [ 10, 8 ],
    [ 25, 10 ],
    [ 50, 13 ],
    [ 75, 18 ],
    [ 90, 23 ],
    [ 97.5, 31 ],
    [ 100, 80 ] ]


  Here are some larger collections.
  
  * For n = 10
    expectation:
    [ [ 'len', 29.39 ] ]

    min: 10
    listMean: 29.39
    listVar: 126.26569999999904
    listStdev: 11.236801146233702
    max: 129
    Percentiles:
    [ [ 0, 10 ],
      [ 2.5, 15 ],
      [ 10, 18 ],
      [ 25, 21 ],
      [ 50, 27 ],
      [ 75, 35 ],
      [ 90, 44 ],
      [ 97.5, 57 ],
      [ 100, 129 ] ]

  * n = 20
    expectation:
    [ [ 'len', 72.69180000000007 ] ]

    min: 28
    listMean: 72.6918
    listVar: 592.7280127599983
    listStdev: 24.34600609463487
    max: 210
    Percentiles:
    [ [ 0, 28 ],
      [ 2.5, 39 ],
      [ 10, 47 ],
      [ 25, 56 ],
      [ 50, 68 ],
      [ 75, 84 ],
      [ 90, 103 ],
      [ 97.5, 133 ],
      [ 100, 210 ] ]

  * for n = 50

    expectation:
    [ [ 'len', 222.59899999999996 ] ]

    min: 100
    listMean: 222.599
    listVar: 3453.7941990000018
    listStdev: 58.76899011383471
    max: 468
    Percentiles:
    [ [ 0, 100 ],
      [ 2.5, 136 ],
      [ 10, 156 ],
      [ 25, 179 ],
      [ 50, 214 ],
      [ 75, 255 ],
      [ 90, 300 ],
      [ 97.5, 366 ],
      [ 100, 468 ] ]

  * n = 100

    expectation:
    [ [ 'len', 516.8920000000004 ] ]

    min: 251
    listMean: 516.892
    listVar: 15413.688336000008
    listStdev: 124.15187608731496
    max: 1195
    Percentiles:
    [ [ 0, 251 ],
      [ 2.5, 335 ],
      [ 10, 385 ],
      [ 25, 427 ],
      [ 50, 498 ],
      [ 75, 580 ],
      [ 90, 677 ],
      [ 97.5, 826 ],
      [ 100, 1195 ] ]


  * If we already have 99 cards (of 100), how many must we buy to get the last (100th) card?
    Note: The values has been adjusted in the output (len-99):

    expectation:
    [ [ 'len', 99.90550000000012 ] ]

    Credible interval for len (94%): [ 1, 285 ]

    min: 1
    listMean: 99.9055
    listVar: 9779.41256974999
    listStdev: 98.89091247303763
    max: 773
    Percentiles:
    [ [ 0, 1 ],
      [ 2.5, 3 ],
      [ 10, 11 ],
      [ 25, 30 ],
      [ 50, 70 ],
      [ 75, 137 ],
      [ 90, 235 ],
      [ 97.5, 369 ],
      [ 100, 773 ] ]

  (Cf my (Swedish) page on simulating with R: http://www.hakank.org/sims/simulering.html )
  

*/

var model = function() {
    var n = 6
    // var n = 10
    // var n = 20
    // var n = 50
    // var n = 100

    var f = function(a) {
        if (_.uniq(a).length == n) {
            return a
        } else {
            var d = 1+randomInteger(n)
            return f(a.concat(d))
        }
    }

    var a = f([])
    // We have n-1 cards, how many do we have to buy to get the last (n'th) card?    
    // var a = f(_.range(1,n)) 
    var len = a.length

    return {
        // a:a,
        len:len,
        // len:len-n+1 // For the special case
    }
    
}

// Enumerate give way to low values since it try to enumerate all from length 1 and up
// var d = Infer({method:"enumerate",maxExecutions:10000},model) 
// var d = Infer({method:"rejection",samples:10000},model)
var d = Infer({method:"SMC",particles:2000},model)

exp_map_all(d)

showCredibleInterval(d,"len",0.94) // This crashes for large samples, e.g. 100000

var ps = [0,2.5,10,25,50,75,90,97.5,100] // quantiles
show_stats(d,"len",ps)
