/*
  How much differs the mean from random selection of (discrete) uniform distribution?
  Here we take n samples from 1..n.

  For n=10, there is a small chance that the mean is >= 8, about 0.0023
  The exact value (from Model 2) is 0.0028197500000000115.

  * Model 1: Using randomInteger (1..10) with Rejection
  * Model 2: Using multinormial with Enumerate (exact)
  * Model 3: Parameter estimation from the results in Model 2 (100 samples)

*/

/*
  Using 1+randomInteger and rejection:

  * For n=10:
  Marginals:
  m
  Marginal:
    5.4 : 0.04420000000000003
    5.5 : 0.04340000000000001
    5.3 : 0.04300000000000001
    5.7 : 0.04240000000000002
    5.8 : 0.042100000000000005
    5.6 : 0.042000000000000016
    6 : 0.04160000000000002
    5.1 : 0.041000000000000016
    5.2 : 0.04060000000000001
    5.9 : 0.039300000000000015
    5 : 0.03720000000000002
    6.1 : 0.03680000000000001
    4.9 : 0.03350000000000002
    6.3 : 0.03260000000000002
    4.7 : 0.031800000000000016
    4.8 : 0.03170000000000002
    6.2 : 0.029100000000000008
    6.4 : 0.027200000000000012
    4.6 : 0.026200000000000015
    4.5 : 0.024900000000000005
    6.5 : 0.02450000000000001
    6.6 : 0.021600000000000008
    4.4 : 0.020700000000000003
    6.7 : 0.017500000000000022
    4.3 : 0.01650000000000001
    4.2 : 0.016200000000000006
    6.8 : 0.015800000000000015
    6.9 : 0.014000000000000007
    4.1 : 0.013800000000000017
    7 : 0.01160000000000001
    3.9 : 0.011400000000000013
    4 : 0.011200000000000005
    7.1 : 0.010400000000000006
    7.2 : 0.008400000000000005
    3.8 : 0.007800000000000007
    3.7 : 0.006200000000000006
    7.3 : 0.006200000000000006
    7.4 : 0.004600000000000004
    3.6 : 0.004100000000000005
    7.5 : 0.0034000000000000037
    3.5 : 0.003100000000000003
    7.6 : 0.0026000000000000016
    3.3 : 0.002500000000000003
    3.4 : 0.002300000000000002
    7.7 : 0.0022000000000000023
    3.2 : 0.0018000000000000013
    7.8 : 0.0017000000000000016
    7.9 : 0.0015000000000000007
    3.1 : 0.001000000000000001
    3 : 0.0009000000000000006
    2.9 : 0.0008000000000000009
    8.1 : 0.0006000000000000003
    8 : 0.0005000000000000006
    8.2 : 0.00040000000000000045
    2.8 : 0.0003000000000000001
    8.6 : 0.0003000000000000001
    2.6 : 0.0003000000000000001
    8.5 : 0.0003000000000000001
    2.5 : 0.00019999999999999985
    8.4 : 0.00010000000000000009
    8.8 : 0.00010000000000000009
  p
  Marginal:
    false : 0.9977
    true : 0.0023

  expectation:
  [ [ 'm', 5.507120000000003 ], [ 'p', 0.0023 ] ]

  quantiles( [ 0.0001, 0.001, 0.01, 0.1, 0.5, 0.9, 0.99, 0.999, 0.9999 ] ):
  [ 2.5, 2.9, 3.4, 4.3, 5.5, 6.7, 7.6, 8.1, 8.6 ]


*/
var model = function() {
    var n = 10
    var sample = repeat(n,function() {1+randomInteger(n)})
    var m = listMean(sample)
    var s = sum(sample)
    var p = m >= 8
    return {
        m:m,
        s:s,
        p:p,
    }
}

var d = Infer({method:"rejection",samples:10000},model)
// var d = Infer({method:"SMC",particles:10000,rejuvSteps:5},model)
// var d = Infer({method:"enumerate"},model)

exp_map_all(d,["marginals","expectation"])

var qs = [0.0001,0.001,0.01,0.1,0.5,0.9,0.99,0.999,0.9999]
console.log("quantiles(",qs,"):")
console.log(quantiles(function() {sample(d)["m"]},qs,10000))

/*
  Using multinomial and Enumerate (exact):

  Marginals:
  m
  Marginal:
    5.5 : 0.04324576400000006
    5.6 : 0.04300004499999997
    5.4 : 0.043000044999999903
    5.7 : 0.042270910000000134
    5.3 : 0.04227091000000006
    5.2 : 0.0410820025000002
    5.8 : 0.041082002499999895
    5.9 : 0.039471355000000305
    5.1 : 0.039471354999999764
    5 : 0.03748943890000006
    6 : 0.037489438899999894
    6.1 : 0.03519663399999998
    4.9 : 0.035196633999999664
    4.8 : 0.0326602869999999
    6.2 : 0.032660286999999885
    4.7 : 0.029951548000000064
    6.3 : 0.029951548000000022
    4.6 : 0.027142180999999967
    6.4 : 0.027142180999999856
    6.5 : 0.024301538800000275
    4.5 : 0.02430153879999992
    6.6 : 0.021493874499999968
    4.4 : 0.021493874499999968
    4.3 : 0.018776131000000043
    6.7 : 0.018776130999999883
    6.8 : 0.01619630650000028
    4.2 : 0.01619630649999988
    4.1 : 0.013792438000000063
    6.9 : 0.013792437999999966
    7 : 0.011592197200000093
    4 : 0.01159219720000001
    7.1 : 0.00961305400000008
    3.9 : 0.009613054000000044
    7.2 : 0.007862932000000026
    3.8 : 0.00786293199999997
    7.3 : 0.0063412580000000145
    3.7 : 0.006341257999999982
    3.6 : 0.0050402935000000175
    7.4 : 0.0050402935000000175
    7.5 : 0.0039466306000000085
    3.5 : 0.003946630599999981
    7.6 : 0.003042737500000006
    3.4 : 0.0030427374999999895
    7.7 : 0.0023084500000000044
    3.3 : 0.002308449999999988
    7.8 : 0.001722325000000008
    3.2 : 0.0017223249999999974
    7.9 : 0.0012628
    3.1 : 0.001262799999999992
    8 : 0.0009091270000000008
    3 : 0.000909126999999996
    8.1 : 0.0006420700000000023
    2.9 : 0.0006420699999999955
    8.2 : 0.0004443725000000031
    2.8 : 0.00044437249999999996
    8.3 : 0.0003010150000000019
    2.7 : 0.00030101500000000034
    2.6 : 0.00019929250000000153
    8.4 : 0.00019929250000000047
    2.5 : 0.00012874840000000047
    8.5 : 0.0001287484
    8.6 : 0.00008100400000000032
    2.4 : 0.00008100400000000004
    8.7 : 0.0000495220000000001
    2.3 : 0.00004952199999999992
    8.8 : 0.000029338000000000118
    2.2 : 0.00002933799999999996
    8.9 : 0.000016786000000000103
    2.1 : 0.000016785999999999954
    9 : 0.000009236799999999996
    2 : 0.000009236799999999962
    1.9 : 0.0000048620000000000155
    9.1 : 0.000004862000000000007
    9.2 : 0.0000024310000000000035
    1.8 : 0.0000024309999999999993
    9.3 : 0.0000011440000000000008
    1.7 : 0.0000011440000000000008
    9.4 : 5.005000000000002e-7
    1.6 : 5.004999999999994e-7
    1.5 : 2.0020000000000027e-7
    9.5 : 2.0020000000000027e-7
    9.6 : 7.150000000000002e-8
    1.4 : 7.150000000000002e-8
    9.7 : 2.2000000000000018e-8
    1.3 : 2.1999999999999942e-8
    1.2 : 5.499999999999985e-9
    9.8 : 5.499999999999985e-9
    9.9 : 9.999999999999972e-10
    1.1 : 9.999999999999972e-10
    10 : 9.999999999999996e-11
    1 : 9.999999999999996e-11
  p
  Marginal:
    false : 0.9971802500000001
    true : 0.0028197500000000115

  expectation:
  [ [ 'm', 5.500000000000001 ], 
    [ 'p', 0.0028197500000000115 ] ]

*/
console.log("\nModel 2: multinomial and Enumerate (exact):")
var model2 = function() {
    var n = 10
    // Get the "coefficients" for each value 1..n
    var sample = multinomial(mapN(function() {1/n},n),n)
    // Multiply each coefficient with its value
    var mults = mapN(function(i) {(i+1)*sample[i]},sample.length)
    var m = listMean(mults)
    var p = m >= 8

    return {
        m:m,
        p:p,
    }
}
var d2 = Infer({method:"enumerate"},model2)
exp_map_all(d2,["marginals","expectation"])
console.log("quantiles(",qs,"):")
console.log(quantiles(function() {sample(d2)["m"]},qs,10000))

/*
  Get 100 values from Model 2 and try to estimate the parameters
  for a gaussian distribution.

  Parameter estimation:
  expectation:
  [ [ 'mu', 5.364837347091898 ],
    [ 'sigma', 0.9545798263196841 ],
    [ 'post', 5.3916784771349 ] ]

*/
console.log("\nParameter estimation:")
var sim = repeat(100,function() {sample(d2)["m"]})

var model3 = function() {
    var mu = uniform(0,10)
    var sigma = uniform(0,5)

    mapIndexed(function(i,val) {
        observe(Gaussian({mu:mu,sigma:sigma}),val)
    }, sim)

    var post = gaussian(mu,sigma)
    return {
        mu:mu,
        sigma:sigma,
        post:post,
    }
}

var d3 = Infer({method:"SMC",particles:1000},model3)
exp_map_all(d3,["expectation"])
