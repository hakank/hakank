/*

  Probability distributions in WebPPL.

  Here are several probability distributions in WebPPL, including
  variants of the built-in distributions.

  They are taken from the files 
    *_dist.wppl 
  at http://hakank.org/wppl/

  Note: 
  - all distribtutions are called <distribution>_dist
  - most of the implementations are from the excellent
    Handbook of probability distributions.

  Usage:
  $ webppl --require hakank_utils model.wppl
  
*/


/*

  Bernoulli distribution
  Binomial distribution

  From Handbook on probability distributions, page 8
  """
  It is easy to simulate Bernoulli distribution with the following heuristic:
  * generate U from a uniform distribution,
  * compute X as 1 if U <= p and 0 otherwise.

  The binomial distribution is obtained by summing n i.i.d. Bernoulli random variates.
  """
 
  Example:
  var model = function() {

    var p = 0.8;
    var n = 10;
    var bern = bernoulli_dist(p);
    var bern2 = bernoulli(p);
    
    var binom = binomial_dist(p,n);
    var binom2 = binomial(p,n);    

    return {
        bern:bern,
        bern2:bern2,
        binom:binom,
        binom2:binom2,
    }
  }

  http://www.hakank.org/webppl/binomial_dist.wppl

*/
var bernoulli_dist = function(p) {
    var u = uniform(0,1);
    return u <= p;
}

var binomial_dist = function(p,n) {
    return sum(mapN(function(i) { return bernoulli_dist(p) }, n));
}


/*
  Cauchy distribution

  Note: Even if the generation algorithm seems to be exactly the same as
  the built-in Cauchy there are quite different results. However, we see 
  the same effect of wildly different results if we compare with to
  runs of the built-in Cauchy. 
  See http://www.hakank.org/webppl/cauchy_dist.wppl for some experiments.

  From Handbook on probability distributions, page 86ff.
  """
  Since the quantile function is F^(-1)(u) = delta+gamma*tan((u-1/2)*pi), we can
  use the inversion function method.
  """

  Compared with the built-in cachy function:
  - delta: location
  - gamma: scale

  Example:

  var model = function() {
    var delta = 1;
    var gamma = 2;
    var g = cauchy_dist(delta,gamma);
    var g2 = cauchy({location:delta,scale:gamma}); // Built-in
    var g3 = cauchy({location:delta,scale:gamma}); // Checking another run
    return {
        g:g,
        g2:g2,
        g3:g3,
    }
  }

  http://www.hakank.org/webppl/cauchy_dist.wppl

*/
var cauchy_dist = function(delta,gamma) {
    var u = uniform(0,1); 
    return delta+gamma*Math.tan((u-1/2)*Math.PI);
}


/*
  Chi distribution

  From Handbook on probability distributions, page 78
  """
  Take the square root of a chi-squared random variable.
  """

  Example:
  var model = function() {
    var k = 2
    var g = chi_dist(k);

    return {
        g:g,

    }
  }

  See http://www.hakank.org/webppl/chi_dist.wppl

*/

var chi_dist = function(k) {
    var x = Math.sqrt(sum(mapN(function(i) { return Math.pow(gaussian(0,1),2)},k)));
    return x;
}


/*

  Chi-squared distribution

  From Handbook on probability distributions, page 76
  """
  For an integer k, just sum the square of k normal variable.
  Otherwise use the algorithm for the gamma distribution.
  """
  
  Example:
  var model = function() {
    var k = 4
    var g = chi_squared_dist(k);
    return {
        g:g,
    }
  }

  See http://www.hakank.org/webppl/chi_squared_dist.wppl

*/
var chi_squared_dist = function(k) {
    var x = sum(mapN(function(i) { return Math.pow(gaussian(0,1),2)},k));
    return x;
}


/*

  Inverse Chi-squared distribution

  From Handbook on probability distributions, page 82
  """
  Simply inverse a chi-squared random variable
  """

  Example:
  var model = function() {
    var k = 4
    var g = inverse_chi_squared_dist(k);
    return {
        g:g,
    }
  }

  http://www.hakank.org/webppl/chi_squared_inverse_dist.wppl
  
*/
var inverse_chi_squared_dist = function(k) {
    var x = 1/sum(mapN(function(i) { return Math.pow(gaussian(0,1),2)},k));
    return x;
}


/*
  Non central Chi-squared distribution

  Note: Experimental
  I'm not sure how to interpret lambda: Is it the sum of the squares of the mu's
  or the actual parameter to the function?
  Also, how do we interpret the case with just k as a parameter, i.e. without lambda?


  From Handbook on probability distributions, page 79
  """
  For integer k degrees of freedom, we can use the definition
  of the sum, i.e. sum k i[n]dependent normal random variables
  N(sqrt(lambda,k),1).
  """
  
  http://www.hakank.org/webppl/chi_squared_non_central_dist.wppl

  Example

     var lambda_func = function(mu) {
       sum(mapN(function(i) {return Math.pow(mu[i],2)},mu.length));    
     }

     var model = function() {
        var k = 5;
        var mu = [1/2,1/3,1/4,1/5,1/6];    
        var lambda = lambda_func(mu);
        var g = non_central_chi_squared_dist(k,lambda);
        var g2 = non_central_chi_squared_dist_mu(k,mu);

        return {
           g:g,
           g2:g2,
           lambda:lambda
        }
    }

*/

var non_central_chi_squared_dist_mu = function(k,mu) {
    var x = sum(mapN(function(i) { return gaussian(mu[i],1)},k));
    return x;
}
// Here we use the lambda direct:
var non_central_chi_squared_dist = function(k,lambda) {
    var x = sum(mapN(function(i) { return gaussian(Math.sqrt(lambda/k),1)},k));
    return x;
}


/*
  Generalized Erlang distribution distribution

  From Handbook on probability distributions, page 64
  """
  The algorithm is very easy simulate independently d random variables
  exponentially E(lambda_j) distributed and sum them.
  """

  Example:
    var model = function() {
      var lambdas = [1,2,3];
      var g = erlang_dist(lambdas);
      return {
        g:g,
      }
    }
  
  http://www.hakank.org/webppl/erlang_dist.wppl

*/
var erlang_dist = function(lambdas) {
    var s = map(function(lambda) { return exponential_dist(lambda)},lambdas);
    return sum(s);
}


/*
  Exponential distribution

  From Handbook on probability distributions, page 53
  """
  Despite the quantile function is q(u) = -1/lambda * log(1-u),
  generally the exponential distribution E(Î») is generated by applying
  -1/lambda * log(U) on a uniform variate U.
  """

  exponential_dist2 is a variant from
  https://en.wikipedia.org/wiki/Inverse_transform_sampling

  var model = function() {
    var lambda = 1/4;
    var g = exponential(lambda); // built-in
    var g2 = exponential_dist(lambda);
    var g3 = exponential_dist2(lambda);        

    return {
        g:g,
        g2:g2,
        g3:g3,
    }
  }

  http://www.hakank.org/webppl/exponential_dist.wppl

*/
var exponential_dist = function(lambda) {
    var u = uniform(0,1);
    return -1*Math.log(u)/lambda;
}

// From https://en.wikipedia.org/wiki/Inverse_transform_sampling
var exponential_dist2 = function(lambda) {
    var u = uniform(0,1);
    return (-1/lambda)*Math.log(1-u);
}


/*
  Inverse Exponential distribution

  From Handbook on probability distributions, page 60
  """
  The algorithm is simply to inverse an exponential variate of parameter
  1/lambda, i.e. (-lambda log(U))-1 for an uniform variable U.
  """

  Example:

  var model = function() {
    var lambda = 1/4;
    
    var g = inverse_exponential_dist(lambda);
    var g2 = exponential(1/lambda); 

    return {
        g:g,
        g2:g2,
    }

  http://www.hakank.org/webppl/exponential_inverse_dist.wppl

*/
var inverse_exponential_dist = function(lambda,t) {
    var u = uniform(0,1);
    return -lambda*Math.log(u);
}

/*
  Shifted Exponential distribution

  From Handbook on probability distributions, page 60
  """
  The random generation is simple: just add Ï„ to the
  algorithm of exponential distribution
  """

  Example:

  var model = function() {
    var lambda = 1/4;
    var t = 1;
    var g2 = shifted_exponential_dist(lambda,t);    

    return {
        g2:g2,
    }
  }

  http://www.hakank.org/webppl/exponential_shifted_dist.wppl
*/
var shifted_exponential_dist = function(lambda,t) {
    var u = uniform(0,1);
    return -1*Math.log(u)/lambda + t ;
}


/*
  Gamma distribution

  Note: Only the integer variant is implemented.

  From Handbook on probability distributions
  page 60
  """
  Simulate a gamma G(a, lambda) is quite tricky for non integer shape parameter.
  Indeed, if the shape parameter a is integer, then we simply sum a exponential
  random variables E(lambda). Otherwise we need to add a gamma variable
  G(alpha-abs(alpha), lambda). This is carried out by an acceptance/rejection method.
  """

  Note this only supports integer a.
  And to compare with the built-in gamma function, we inverse the lambda
  parameter.

  Example:

  var model = function() {
    var a = 4;
    var lambda = 1/2;
    
    var g = gamma_int_dist(a, lambda);
    var g2 = gamma(a,lambda); // built-in method

    return {
        g:g,
        g2:g2,
    }
  }

  http://www.hakank.org/webppl/gamma_dist.wppl

*/
var gamma_int_dist = function(a, lambda) {
    var s = mapN(function(i) { return exponential_dist(1/lambda)},a);
    return sum(s);
}


/*
  Generalized (Transformed) Gamma distribution

  From Handbook on probability distributions, page 67
  """
  Generate a gamma distributed variable (G(Î±, 1)), raise it to power 1/t
  and multiply it by lambda
  """

  Example:

  var model = function() {
    var g = generalized_gamma_dist(3,1/2,1/3);
    return {
        g:g,
    }
  }

  http://www.hakank.org/webppl/gamma_generalized_dist.wppl

*/
var generalized_gamma_dist = function(a,lambda,t) {
    var x = lambda*Math.pow(gamma(a,1),1/t);   
    return x;
}


/*
  Inverse Gamma distribution

  Note: I'm not sure if b (lambda) should be inversed as well since
  WebPPL's gamma seems to handle scale, not lambda...

  From Handbook on probability distributions, page 66
  """
  Simply generate a gamma variable G(Î±, 1/lambda) and inverse it.
  """

  Example:

  var model = function() {
    var g = inverse_gamma_dist(2,4);
    return {
        g:g,
    }
  }

  http://www.hakank.org/webppl/gamma_inverse_dist.wppl

*/
var inverse_gamma_dist = function(a,lambda) {
    var x = 1/gamma(a,lambda)
    return x;
}


/*
  
  Inversed transformed Gamma distribution

  From Handbook on probability distributions
  page 68
  """
  Simply simulate a gamma G(a, 1) distributed variable,
  inverse it, raise it to power 1/a [shouldn't it be 1/t?]
  and mutiply it by lambda.
  """

  Example:

  var model = function() {
    var g = inversed_transformed_gamma_dist(3,2,1);
    return {
        g:g,
    }
  }

  http://www.hakank.org/webppl/gamma_inverse_transformed_dist.wppl

*/
var inversed_transformed_gamma_dist = function(a,lambda,t) {
    var x = Math.pow(1/gamma(a,1),1/t)/lambda;
    return x;
}


/*
  Gaussian distribution

  From Handbook on probability distributions
  page 49
  """
  The Box-Muller algorithm produces normal random variates:
  * generate U, V from a uniform U(0, 1) distribution,
  * compute X = sqrt(-2*log(U))*cos(2*Pi*V) and Y = sqrt(-2*log(U))*sin(2*Pi*V ).
  In outputs, X and Y follow a standard normal distribution (independently).
  ...

  But there appears that this algorithm under estimates the tail
  of the distribution (called the Neave effect, cf. Patard (2007)),
  most softwares use the inversion function method, consist in
  computing the quantile function Î¦-1 of a uniform variate. 
  """

  Example
  var model = function() {
    var g = gaussian(0,1); // Built-in version
    var g2 = gaussian01(); // This version
    var mean = 100;
    var std = 10;
    var g3 = gaussian(mean,std); // Built-in version
    var g4 = gaussian_dist(mean,std); // This version
    return {
        g:g,
        g2:g2,
        g3:g3,
        g4:g4,
    }
  }

  http://www.hakank.org/webppl/gaussian_dist.wppl

*/
var gaussian01 = function() {
    var u = uniform(0,1);
    var v = uniform(0,1);
    // var x = Math.sqrt(-2*Math.log(u))*Math.cos(2*Math.PI*v);
    var y = Math.sqrt(-2*Math.log(u))*Math.sin(2*Math.PI*v);

    // return x;
    return y;    
}

var gaussian_dist = function(mean,std) {
    return mean + (gaussian01() * std);
}


/*
  Geometric distribution

  From Handbook on probability distributions
  page 19
  Expectation: (1-p)/p
  """
  A basic algorithm is to use i.i.d. Bernoulli variables as follows:
  * initialize X to 0 and generate U from an uniform distribution,
  * while U > p do ; generate U from an uniform distribution; X = X + 1;
  * return X.
  """
  
  Example:

  var model = function() {
    var p = 0.9;
    var g = geometric_dist(p);
    return {
        g:g
    }
  }

*/
var geometric1 = function(p,x) {
    var u = uniform(0,1);
    return u > p ? geometric1(p,x+1) : x;
}

var geometric_dist = function(p) {
    return geometric1(p,0);
}


/*
  Zero Modified (Inflated) Geometric distribution

  From Handbook on probability distributions
  page 21
  """
  While for the zero-modified geometric distribution, it is a little bit tricky
  * generate U from an uniform distribution
  * if U < p, then X = 0
  * otherwise
    - initialize X to 1 and generate U from an uniform distribution
    - while U > q do ; generate U from an uniform distribution; X = X + 1;
  * return X
  """

  Example:
  var model = function() {
    var p = 0.9; // Probability of zero
    var q = 0.4;

    var g = zero_inflated_geometric_dist(p,q);
    
    return {
        g:g
    }
  }

  http://www.hakank.org/webppl/geometric_zero_modified_dist.wppl

*/
var zero_inflated_geometric1 = function(p,q,x) {
    var u = uniform(0,1);    
    return u > q ? zero_inflated_geometric1(p,q,x+1) : x;
}

// p is the probability of 0
var zero_inflated_geometric_dist = function(p,q) {
    var u = uniform(0,1);
    if (u < p) {
        return 0;
    } else {
        return zero_inflated_geometric1(p,q,1);
    }
}


/*
  Zero truncated Geometric distribution

  From Handbook on probability distributions, page 21
  Zero truncated Geometric distribution is a Geometric distribution 
  but zero is not a possible value.
   
  It's used for generating a Pascal distribution, see pascal_dist

  Example:

  var model = function() {
    var p = 0.9;
    var g = geometric_zero_truncated_dist(p);
    return {
        g:g
    }
  }
 
  http://www.hakank.org/webppl/geometric_zero_truncated_dist.wppl

*/
var geometric_zero_truncated1 = function(p,n) {
    var u = uniform(0,1);
    return u > p ? geometric_zero_truncated1(p,n+1) : n;
}

var geometric_zero_truncated_dist = function(p) {
    return geometric_zero_truncated1(p,1);
}


/*
  Hypergeometric distribution

  https://en.wikipedia.org/wiki/Hypergeometric_distribution
  """
  T]he probability of k successes (random draws for which the object 
  drawn has a specified feature) in n draws, without replacement, from 
  a finite population of size N that contains exactly K objects with 
  that feature, wherein each draw is either a success or a failure. 
  In contrast, the binomial distribution describes the probability of 
  k successes in n draws with replacement. 
  """

  Cf https://github.com/distributions-io/hypergeometric-random/blob/master/lib/number.js

  Hypergeometric:
  What is the probability that we draw exactly k "success" objects
  of the n drawn objects of total N objects where there are in total
  K "success" objects

  k: number of successes we want to check
  N: total number of objects
  K: total number of success objects
  n: number of draws

  Here are two versions:
  - hypergeometric_dist(k,N,K,n):
    Probability of exactly k successes.

  - hypergeometric_count(k,N,K,n)
    The number of found successes

  Example:

  var model = function() {

    // total: 5 green and 45 red marbles
    // drawn: 4 green marbles, 6 red marbles
    var K = 5; // total green marbles: 4 drawn + 1 not drawn
    var N = 50; // total marbles: 5 green + 45 red marbles
    
    var k = 4; // drawn green_marbles
    // var k = 5; // drawn green_marbles    
    var n = 10 // total drawn green + red marbles
    
    var g = hypergeometric(k,N,K,n);
    // var g = hypergeometric_count(k,N,K,n); // Count version
    
    return {
        g:g
    }
    
  }

  http://www.hakank.org/webppl/hypergeometric_dist.wppl  

*/
var hypergeometric1 = function(k,N,K,n,count) {
    if (n==0 || K<= 0) {
        return count;
    } else {
        // we have K successes left and N objects left
        var p = K/N; // probability of drawing a success object
        if (flip(p)) {
            // We drew a success:
            // - decrement the total objects (N)
            // - decrement the number of "success" objects (K)
            // - decrement the number of drawn objects (n)
            // - increment the number of successful draws (count)
            return hypergeometric1(k,N-1,K-1,n-1,count+1);
        } else {
            // We drew a failure:
            // - decrement the total objects (N)
            // - decrement the number of drawn objects (n)
            return hypergeometric1(k,N-1,K,n-1,count);
        }
    }
}

var hypergeometric_dist = function(k,N,K,n) {
    var res = hypergeometric1(k,N,K,n,0);
    return res == k;
}

// Return the number of found successes.
var hypergeometric_count = function(k,N,K,n) {
    var res = hypergeometric1(k,N,K,n,0);
    return res;
}


/*
  Laplace distribution

  From Handbook on probability distributions
  page 73
  """
  Let U be a uniform variate. Then the algorithm is
  * V = U - 1/2
  * X = m + sigma*sign(V ) log(1 - 2|V|)
  return X
  """

  Example:
  var model = function() {
    var mu = 0;
    var sigma = 1;
    var g = laplace_dist(mu,sigma);
    var g2 = laplace(mu,sigma); // built-in

    return {
        g:g,
        g2:g2,

    }
  }

  http://www.hakank.org/webppl/laplace_dist.wppl
  
*/
var laplace_dist = function(mu,sigma) {
    var u = uniform(0,1);
    var v = u-1/2;
    var x = mu + sigma*Math.sign(v)*Math.log(1-2*Math.abs(v));
    
    return x;
}


/*
  Log Gamma distribution

  From Handbook on probability distributions, page 69
  """
  Simply simulate a gamma G(k, 1) distributed variable and returns a + b log(X).
  """

  Example:
  var model = function() {
     
    var g = log_gamma_dist(3,2,1);

    return {
        g:g,
    }
  }
  
  http://www.hakank.org/webppl/log_gamma_dist.wppl

*/
var log_gamma_dist = function(k,a,b) {    
    return a+b*Math.log(gamma(k,1));
}


/*
  LogNormal distribution

  From Handbook on probability distributions, page 51
  """
  Once we have generated a normal variate, it is easy to generate
  a log-normal variate just by taking the exponential of normal
  variates.
  """

  Example:
  var model = function() {   
    var g = log_normal_dist(0,1);
    return {
        g:g,
    }
  }

  http://www.hakank.org/webppl/log_normal_dist.wppl

*/
var log_normal_dist = function(mu,sigma) {
    var g = gaussian(mu,sigma);
    return Math.exp(g);    
}


/*
  Shifted LogNormal distribution

  From Handbook on probability distributions, page 53
  """
  Once we have generated a normal variate, it is easy to generate a
  log-normal variate just by taking the exponential of normal variates and
  adding the shifted parameter Î½.
  """

  Example:

  var model = function() {
     
    var g = shifted_log_normal_dist(0,1,4);

    return {
        g:g,
    }
  }

  http://www.hakank.org/webppl/log_normal_shifted_dist.wppl

*/
var shifted_log_normal_dist = function(mu,sigma,v) {
    var g = gaussian(mu,sigma);
    return Math.exp(g) + v;    
}


/*
  Negative Binomial distribution
  
  From Handbook on probability distributions, page 22ff
  """
  The algorithm to simulate a negative binomial distribution NB(m, p) 
  is simply to generate m random variables geometrically distributed 
  and to sum them.
  """

  Example:
  var model = function() {
    var d = negative_binomial_dist(3,0.7);
    return {
        d:d,
        p:(d >= 4),
    }
  }

  http://www.hakank.org/webppl/negative_binomial_dist.wppl

*/
var negative_binomial_dist = function(m,p) {
    var g = mapN(function() { return geometric_dist(p)}, m);
    return sum(g);
}


/*
  Pareto distribution

  See https://en.wikipedia.org/wiki/Pareto_distribution
  and 
  https://math.stackexchange.com/questions/1777367/how-to-generate-a-random-number-from-a-pareto-distribution

  Example:

  var model = function() {
    var shape = 4; // a
    var scale = 6820; // b
    var p = pareto_dist(shape,scale);
    return {
        p:p
    }
  }

  http://www.hakank.org/webppl/pareto_dist.wppl

*/
var pareto_dist = function(shape,scale) {
    var u = uniform(0,1);
    var x = scale/Math.pow(1-u,1/shape)
    return x;
}


/*
  Pareto distribuitions, types I..IV

  From Handbook on probability distributions, page 95
  """
  ... Therefore algorithms for random generation are simply
  * for P_I(sigma, alpha) distribution, F^-1(u)= sigma*U^(-1/alpha)
  * for P_II(mu, sigma, alpha) distribution, F^-11(u) = sigma*(U^(-1/alpha - 1) + mu,
  * for P_III(mu, sigma, gamma) distribution, F^-1(u) = sigma*(U^(-1)-1)^gamma + mu,
  * for P_IV(mu, sigma, alpha[, gamma]) distribution, F^-1(u) = sigma*(U^(-1/alpha)-1)^gamma + mu,
  where U is an uniform random variate.
  """
  Note: P_IV is missing the fourth parameter gamma in the text.


  Example:
  var model = function() {
    var g1 = pareto_i_dist(2,3);
    var g2 = pareto_ii_dist(2,3,1);
    var g3 = pareto_iii_dist(1,1,1);
    var g4 = pareto_iv_dist(0,1,1,2);
    return {
        g1:g1,
        g2:g2,
        g3:g3,
        g4:g4,
    }
  }

  http://www.hakank.org/webppl/pareto_dist2.wppl

*/
var pareto_i_dist = function(sigma,alpha) {
    var u = uniform(0,1); 
    return sigma*Math.pow(u,(-1/alpha));
}

var pareto_ii_dist = function(mu,sigma,alpha) {
    var u = uniform(0,1);
    return sigma*(Math.pow(u,-1/alpha)-1) + mu;
}
    
var pareto_iii_dist = function(mu,sigma,gamma) {
    var u = uniform(0,1); 
    return sigma*Math.pow(Math.pow(u,-1)-1,gamma) + mu;
}

var pareto_iv_dist = function(mu,sigma,alpha,gamma) {
    var u = uniform(0,1); 
    return sigma*Math.pow(Math.pow(u,-1/alpha)-1,gamma) + mu;
}


/*
  Generalized Pareto distribution

  From Handbook on probability distributions
  page 101
  """
  We have an explicit expression for the quantile function
  F^-1(u) =
     if xi != 0:
        eta + (sigma/xi)*( (1-u)^(-xi) - 1)
     if xi == 0:
        eta - sigma*log(1-u)
  thus we can use the inversion function method to generate
  GPD variables.
  """

  Example:
  var model = function() {
    var g = generalized_pareto_dist(1,1,-5/4);  
    return {
        g:g,
    }
  }

  http://www.hakank.org/webppl/pareto_generalized_dist.wppl
  
*/
var generalized_pareto_dist = function(eta,sigma,xi) {
    var u = uniform(0,1);
    if (xi != 0) {
        return eta + (sigma/xi)*( Math.pow(u,-xi) - 1);
    } else {
        return eta + sigma*Math.log(u);
    }
}


/*
  Inverse Pareto distribtion

  From Handbook on probability distributions, page 98
  """
  Simply inverse a Pareto II variable.
  """

  Example:
  var model = function() {
    var g = inverse_pareto_dist(2,1,1);  
    return {
        g:g,
    }
  }

  http://www.hakank.org/webppl/pareto_inverse_dist.wppl

*/
var inverse_pareto_dist = function(mu,sigma,alpha) {
    return 1/pareto_ii_dist(mu,sigma,alpha);
}

/*
  Pascal distribution

  From Handbook on probability distributions, page 25
  """
  The negative binomial distribution can be constructed by summing 
  m geometric distributed variables G(p). The Pascal distribution is 
  got from summing n geometrically distributed G0(p) variables.
  Thus possible values of the Pascal distribution are in {n, n+ 1, ...}.

  ...

  The link between Pascal distribution Pa(n,p) and the negative 
  binomial distribution BN(n,p) is to substract the constant n, i.e. 
  if X ~ Pa(n,p) then X-n ~ BN(n, p).
  """

  Example:
  var model = function() {
    // Cf negative_binomial_test.wppl
    var d = pascal(3,0.5);
    var p = d <= 6
    return {
        d:d,
        p:p,
    }
  }

  http://www.hakank.org/webppl/pascal_dist.wppl

*/
var pascal_dist = function(m,p) {
    var g = mapN(function() { return geometric_zero_truncated_dist(p)}, m);
    return sum(g);
}


/*
  Poisson distribution

  From Handbook on probability distributions, page 14
  """
  A basic way to generate Poisson random variate is the following:
  * initialize variable n to 0, l to exp(-lambda) and P to 1,
  * do
    â€“ generate U from a uniform distribution,
    â€“ P = P * U,
    â€“ n = n 0 1,
    while P >= l,
  return n âˆ’ 1.
  See Knuth (2002) for details.
  """
  Note: n is the counter, p2 is the acculumated value

  Example:
  var model = function() {
    var n = 4;   
    var p = poisson(n); // built-in
    var p2 = poisson_dist(n);
    return {
        p:p,
        p2:p2
    }
  }

  http://www.hakank.org/webppl/poisson_dist.wppl

*/
// Note: n is the counter, p2 is the acculumated value
var poisson_dist1 = function(lambda,n,p2) {
    var l = Math.exp(-lambda);
    var u = uniform(0,1);
    var p = p2*u;
    return p >= l ? poisson_dist1(lambda,n+1,p) : n;
}

var poisson_dist = function(lambda) {
    return poisson_dist1(lambda,0,1);
}


/*
  Zero Modified Poisson distribution

  
  From Handbook on probability distributions, page 17
  """
  The zero-modified version P(lambda, p) is a little bit tricky.
  We need to use the following heuristic:
  * generate U from an uniform distribution
  * if U < p, then X = 0
  * otherwise
    - do; generate X Poisson distributed P(lambda); while X = 0
  * return X
  """

  Example:
  var model = function() {

    var lambda = 4;
    var p = 0.2;
    var p = zero_modified_poisson_dist(lambda,p);

    return {
        p:p,
    }
  }

  http://www.hakank.org/webppl/poisson_zero_modified_dist.wppl

*/
var zero_modified_poisson_dist = function(lambda,p) {
    var u = uniform(0,1);
    if (u < p) {
        return 0;
    } else {
        var p2 = poisson(lambda);
        return p2 != 0 ? p2 : zero_modified_poisson_dist(lambda,p);
    }
}


/*
  Zero Truncated Poisson distribution

  Algorithm from Handbook on probability distributions,
  page 16
  """
  The basic algorithm for the zero-truncated version P0(lambda) is simply
  * do; generate X Poisson distributed P(Î»); while X = 0
  * return X
//
  In output, we have a random variate in N âˆ— .
  The zero-modified version P(Î», p) is a little bit tricky. We need to use the following heuristic:
  - generate U from an uniform distribution
  - if U < p, then X = 0
  - otherwise
  - do; generate X Poisson distributed P(Î»); while X = 0
  - return X
  """

  Example:
  var model = function() {

    var lambda = 4;
    
    var p = zero_truncated_poisson_dist(lambda);

    return {
        p:p,
    }
  }

  http://www.hakank.org/webppl/poisson_zero_truncated_dist.wppl
  
*/
// Note: n is the counter, p2 is the acculumated value
var zero_truncated_poisson_dist = function(lambda) {
    var p = poisson(lambda);
    return p != 0 ? p : zero_truncated_poisson_dist(lambda);
}


/*
  Student-T distribution

  From Handbook on probability distributions
  page 85
  """
  The algorithm is simply
  * generate a standard normal distribution N
  * generate a chi-squared distribution C
  * return sqrt(d)*N/sqrt(C)
  """

  Example:
  var model = function() {
    var d = 4;
    var g = student_t_dist(d);

    return {
        g:g,

    }
  }
  
  http://www.hakank.org/webppl/student_t_dist.wppl

*/
var student_t_dist = function(d) {
    var N = gaussian(0,1);
    var C = chi_squared_dist(d);
    return Math.sqrt(d)*N/Math.sqrt(C);
}


/*
  Triangular distribution

  From Handbook on probability distributions, page 38
  """
  Expectation: (a+b+c)/3.
  """

  Example:
  var model = function() {
    var a = 0;
    var b = 3;
    var c = 10;
    var g = triangular_dist(a,b,c);
    return {
        g:g
    }
  }

  http://www.hakank.org/webppl/triangular_dist.wppl

*/
var triangular_dist = function(a,b,c) {
    var u = uniform(0,1);
    var v = uniform(0,1);
    var cc = (c-a)/(b-a);
    var x = a + (b-a) * ((1-cc)*Math.min(u,v) + cc*Math.max(u,v));
    return x;
}


/*
  Discrete Uniform distribution

  From Handbook on probability distributions
  page 8
  """
  The algorithm is simply:
  - generate U from a uniform distribution
  - compute the generated index as I = ceiling(n*U)
  - finally X is k[I]
  """

  Example:
  var model = function() {
    var a = _.range(10);
    var g = uniform_discrete_dist(a);
    return {
        g:g,
    }
  }

  http://www.hakank.org/webppl/uniform_discrete_dist.wppl

*/
var uniform_discrete_dist = function(a) {
    var n = a.length;
    var u = uniform(0,1);
    var ix = Math.ceil(n*u)-1; // Adjust for base 0
    return a[ix];
}


/*
  Weilbull distribution


  From Handbook on probability distributions
  page 79
  """
  Using the inversion function method, we simply need to compute
  beta(-log(1-U))^1/eta) for the first parametrization or
  (-log(1-U)/t)^(1/eta) for the second one where U is an
  uniform variate.
  """

  Example:
  var model = function() {
    var g = weibull_dist(4,3);
    return {
        g:g,
    }
  }

  http://www.hakank.org/webppl/weibull_dist.wppl

*/
var weibull_dist = function(eta,beta) {
    var u = uniform(0,1);
    var x = beta*Math.pow(-Math.log(1-u),1/eta)
    
    return x;
}


/*
  
  Inverse Weibull distribution

  From Handbook on probability distributions, page 72
  """
  Simply generate a Weibull variable W(1/beta,eta) and inverse it.
  """
  Note: I'm a little confused here since the weibull dist is noted as
  W(eta,beta) according to the Weibull Distribution entry.
  
  Example:
  var model = function() {

    var eta = 4;
    var beta = 2;
    var g = inverse_weibull_dist(beta,eta);
    var expect = inverse_weibull_expectation(beta,eta);

    return {
        g:g,
        expect:expect,
    }
  }

  http://www.hakank.org/webppl/weibull_inverse_dist.wppl


*/
var inverse_weibull_dist = function(beta,eta) {
    var x = 1/weibull_dist(eta,1/beta);
    
    return x;
}

var inverse_weibull_expectation = function(beta,eta) {
    return beta*gamma_func(1-1/eta);
}
