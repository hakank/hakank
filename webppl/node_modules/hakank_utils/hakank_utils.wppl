/*
    Show marginals, expectations, MAP for variables.

    Sample Usage:
        var model = function() { 
            // ...
            return {
                x:x,
                y:y,
            }
        }
        var d = Infer(model)
        exp_map(d,["x","y"]))
        exp_map(d,["x","y"],["marginals","expectation"]))

*/
var exp_map = function(d,arr,types) {
    if (types === undefined) {
        console.log("Marginals:");
        map(function(a) {console.log(a);console.log(marginalize(d, a)) }, arr);
        console.log("\nexpectation:");
        console.log(map(function(a) { [a,expectation(marginalize(d, a))] }, arr));
        console.log("\nMAP:");
        console.log(map(function(a) { [a,MAP(marginalize(d, a))] }, arr));
        console.log()
    } else {
        if (types.includes("marginals")) {
            console.log("Marginals:");
            map(function(a) {console.log(a);console.log(marginalize(d, a)) }, arr);
            console.log();            
        }
        if (types.includes("expectation")) {
            console.log("expectation:");
            console.log(map(function(a) { [a,expectation(marginalize(d, a))] }, arr));
            console.log();            
        }
        if (types.includes("MAP")) {
            console.log("MAP:");
            console.log(map(function(a) { [a,MAP(marginalize(d, a))] }, arr));
            console.log();
        }
    }

}


var exp_map_all = function(d,types) {
    var arr = Object.keys(d.support()[0])
    if (types === undefined) {
        exp_map(d,arr)
    } else {
        exp_map(d,arr,types)
    }
}

/* 
   Percentiles of an array.

   Example usage:
        var model = function() {
            // ...
            return {x:x}
        }
        var d = Infer(model)
        var m = marginalize(d, "x");
        var s = m.supp;
        var ps = [0,2.5,25,50,75,97.5,100];
        var pcts = percentile(s,ps);

   From https://en.wikipedia.org/wiki/Percentile
   Using Nearest rank method
*/ 
var percentile = function(values,ps) {
    var len = values.length;
    var sorted = sort(values);
    var pcts = map(function(p) {var v = Math.ceil(len*p/100);
                                return sorted[Math.max(1,v)-1]},
                   ps);
    return pcts;
}

/*
  Using percentiles in the range 0..1 instead of 0..100.
*/
var percentile_pct = function(values,ps) {
    var len = values.length;
    var sorted = sort(values);
    var pcts = map(function(p) {var v = Math.ceil(len*p);
                                return sorted[Math.max(1,v)-1]},
                   ps);
    return pcts;
}


/*
  Show statistics for a variable (v)

  Example usage:
    var model = function() {
       // ....
       export {
         x:x,
         y:y,
       }
    }
    var d = Infer(model);
    var ps = [0,2.5,25,50,75,97.5,100]; // quantiles
    show_stats(d,"x",ps);
    show_stats(d,"y",ps);

    or with default ps:
    show_stats(d,"y");

*/
var show_stats1 = function(d,v,ps) {
    // var psx = arguments.length == 2 ? [0,2.5,25,50,75,97.5,100] : ps
    var psx = arguments.length == 2 ? [0,1, 2.5,25,50,75,97.5,99,100] : ps    
    
    console.log("\nvar", v);
    var t = map(function(e) {
        return e.value[v]
    },d.samples);
    console.log("min:", _.min(t));
    var mean = listMean(t);
    console.log("listMean:", mean);
    console.log("max:", _.max(t));
    console.log("listVar:", listVar(t,mean));
    console.log("listStdev:", listStdev(t,mean));
    
    var pcts = percentile(t,ps);
    console.log("Percentiles:");
    console.log(map2(function(e,v) {return [e,v]},psx,pcts));
}


/*
  Calculate the number of bins (for histogram)

  https://en.wikipedia.org/wiki/Histogram

*/
// Square root choice
// num_bins(L) = ceiling(sqrt(L.len)).

// Rice Rule seems to be a little better...
var num_bins = function(values) {
    return 2*Math.ceil(Math.pow(values.length,1/3));
}

/*
    Histogram of an array of values.

    Sample usage:
        var model = function() {
            // ..
            return {
                x:x,
                y:y,
            }
        }
        var d = Infer(model);
        var values = map(function(e) {
            return e.value[v]
        }, d.samples);
        var hist = histogram(values)

*/
var histogram = function(values) {
    // Calculate the number of bins
    var num_bins = num_bins(values);
    return histogram1(values,num_bins);
}


// This is to JS function in hakank_utils.js instead
// It contains the meat of the histogram function.
var histogram1 = function(d,v,ps) {
    return hakank_utils.histogram1(d,v,ps);
}


/*
   Show statistics for a variable (v)

    var model = function() {
       // ..
       return {
           x:x,
           y:y,
       }
    }
    var d = Infer(model);
    var ps = [0,2.5,25,50,75,97.5,100]; // quantiles
    show_stats(d,"x",ps);
    show_stats(d,"y",ps);

    or with default ps:
    show_stats(d,"x");


*/
var show_stats = function(d,v,ps) {
    // var ps1 = arguments.length == 2 ? [0,2.5,25,50,75,97.5,100] : ps 
    var ps1 = arguments.length == 2 ? [0,1, 2.5,25,50,75,97.5,99,100] : ps   
    var psx = _.max(ps1) > 1 ? ps1 : map(function(v) {v*100},ps1)

    console.log("\nvar", v);
    var isEnumerate = d.samples === undefined    
    var t = isEnumerate ? getSamples(d,v,1000) : map(function(e) {return e.value[v]},d.samples)
    var num_samples = t.length
    console.log("Num samples:", num_samples)
    if (num_samples > 25000) {
        console.log("The number of samples (" + num_samples + ") is too big! Please reduce the sample space.")
        return false
    }
    
    var isInt = Number.isInteger(t[0])
    var isNumeric = typeof t[0] === "number"
    
    console.log("min:", _.min(t));
    if (isNumeric) {
        var mean = listMean(t);
        console.log("listMean:", mean);
        console.log("listVar:", listVar(t,mean));
        console.log("listStdev:", listStdev(t,mean));
    }
    console.log("max:", _.max(t));

    console.log("\nPercentiles:");    
    var pcts = percentile(t,psx);
    console.log(map2(function(e,v) {return [e,v]},psx,pcts));

    console.log("\nHistogram (",num_samples,"samples)")
    if (isEnumerate && isInt) {
        console.log("(Enumerate, from probabilities)")
        var marg = marginalize(d,v)
        var supp = sort(marg.supp)
        var dist = marg.getDist()
        var probs = map(function(x) {x.prob},Object.values(dist))
        var max_prob = _.max(probs)
        var scale = 80
        console.log("Value | Prob * 100 | Rel. freq (prob / cumulative prob) " )
        var tt = mapIndexed(function(ix,x){
            var p = dist[x].prob
            var p2 = Math.round(p*1000)/1000
            var val = Math.round(scale*(p/max_prob))
            var s = ("    " + x).slice(-5)
            var vv = ("   " + Math.round(100*p)).slice(-4)
            var cum = Math.round(1000*sum(mapN(function(i) { dist[supp[i]].prob}, ix+1)))/1000
            if (val>= 1) {
                console.log(s,vv,repeat(val,function(){"*"}).join(""),"(",p2,"/",cum,")")
            } else {
                console.log(s,vv,repeat(val,function(){"*"}).join(""),"(",p2,"/",cum,")")
            }
        },supp)

    } else {

        // If integer values, we check all the values,
        // but only if there are < 30 different values
        var coll = collect(t)
        var num_keys = isInt ? Object.keys(coll).length : undefined
        var scale = 80
        if (isInt && num_keys < 40) {
            var keys = Object.keys(coll)
            var values = Object.values(coll)
            var max_value = _.max(values)
            console.log("Value | #Obs | Rel. freq (prob / cumulative prob)" )
            var keys_sorted = sort(map(function(v) {_top.parseInt(v)}, keys),lt)
            var sum_values = sum(values)
            var tt = mapIndexed(function(ix,key) {
                var kk = ("    " + key).slice(-5)
                var value = coll[key]
                var vv = Math.round(scale*(value/max_value))
                var vvs = ("    " + value).slice(-5)
                var prob = Math.round(1000*value/sum_values)/1000
                var prev = sum(mapN(function(k) {coll[keys_sorted[k]]},ix+1))
                var cum = Math.round(1000*prev/sum_values)/1000
                console.log(kk,vvs,rep(vv,"*").join(""),"(",prob,"/",cum,")")
            },keys_sorted)
            
        } else {
            var histogram_t = isInt && num_keys < 30 ? histogram1(t,num_keys-1) : histogram(t)
            var histogram = histogram_t.bins
            if (isNumeric) {
                console.log("Bin interval | #Obs | Rel. freq. (prob / cumulative prob)" )            
                var intervals = histogram_t.intervals
                show_scaled_histogram(histogram,intervals,scale)
            } else {
                // Symbolic keys
                var values = Object.values(histogram)
                var max_value = _.max(values)                
                var tt = map(function(key) {
                    var kk = ("          " + key).slice(-10)
                    var value = coll[key]
                    var vv = Math.round(scale*(value/max_value))
                    var vvs = ("    " + value).slice(-5)                    
                    console.log(kk,vvs,rep(vv,"*").join(""))
                },sort(Object.keys(histogram)))
            }
        }
    }
}

var show_scaled_histogram = function(bins,intervals,scale) {
    if (arguments.length == 1) {
        return scaled_histogram(bins,intervals,80)
    }
    var max_val = _.max(bins)
    var sum_bins = sum(bins)
    var t = mapN(function(i) {
        var val = bins[i]
        var interval = intervals[i]
        var x = Math.round(scale*(val / max_val))
        var ii = ("     " + interval).slice(-6)         
        var vv = ("   " + val).slice(-4)
        var prob = Math.round(1000*val/sum_bins)/1000
        var cum = Math.round(1000*sum(mapN(function(j) { bins[j]},i+1))/sum_bins)/1000
        if (i < bins.length-1 ) {
            console.log(ii,vv,repeat(x,function(){"*"}).join(""),"(",prob,"/",cum,")")
        } else {
            var iii = ("     " + ">"+_.last(intervals)).slice(-6)
            console.log(iii,vv,repeat(x,function(){"*"}).join(""),"(",prob,"/",cum,")")
        }
    },bins.length)
}

/*
    Get samples of key from distribution Dist.

    From https://mhtess.github.io/bdappl/chapters/03-simpleModels.html

    This does not work with results from Enumerate, use getSamples2 for that.
    

*/
var getSamples = function(Dist, key){
    if (Dist.samples !== undefined) {
        // For Rejection, SMC, and MCMC
        return _.map(_.map(Dist.samples, "value"), key)
    } else {
        // For Enumerate which does not have .samples.
        return getSamples2(Dist,key,1000)
    }
}

/*
  getSamples2(dist, variable, num)
  
  This variant works with Enumerate as well as the other methods.
  Note that it samples for the posterior distribution so it's not
  the exact samples that was used.

*/
var getSamples2 = function(d, v, n) {
    var marg = marginalize(d,v)
    return repeat(n, function() {sample(marg)})
}



/*
    Show the credible interval of samples `mySamples  with
    the credibilit mass of `credMass`.

    Sample usage:
        var model = function() {
            // ...
            return {
                x: x,
                y: y,
            }
        }
        var c = getSamples(d, "x")
        display(credibleInterval(c, 0.93))

        or
        display(credibleInterval(getSamples(d,"x"), 0.93))


    From https://mhtess.github.io/bdappl/chapters/03-simpleModels.html

*/
var credibleInterval = function(mySamples, credMass){
    var sortedPts = sort(mySamples)
    var ciIdxInc = Math.ceil(credMass*sortedPts.length)
    var nCIs = sortedPts.length - ciIdxInc
  
    var ciWidth = map(function(i){
      sortedPts[i + ciIdxInc] - sortedPts[i]
    },_.range(nCIs))
  
    var i = _.indexOf(ciWidth, _.min(ciWidth))
    return [sortedPts[i], sortedPts[i+ciIdxInc]]
  }

/*
  Wrapper for credibleInterval

  var model = function() { 
     // ...
     return {
         x:x,
         y:y
     }
  } 
  var d = Infer(model)
  showCredibleInterval(d,"x",0.93)


*/
var showCredibleInterval = function(d, v, credMass) {
    var ci = credibleInterval(getSamples(d,v), credMass)
    console.log("Credible interval for " + v + " (" + 100*credMass + "%):",ci)
}

// This works with results from Enumerate
var showCredibleInterval2 = function(d, v, credMass,n) {
    var ci = credibleInterval(getSamples2(d,v,n), credMass)
    console.log("Credible interval for " + v + " (" + 100*credMass + "%):",ci)
}

/*
  Check if value val is within the (pct*100)% credible interval for 
  the variable d[v].

  var model = function() { 
     // ...
     return {
         x:x,
         y:y
     }
  } 
  var d = Infer(model)
  checkCredibleInterval(d,"x",1.7,0.95)

*/
var checkCredibleInterval = function(d,v,val,pct) {
    var ci = credibleInterval(getSamples(d,v), pct)
    console.log("Conclusion for",pct*100,"% interval:")
    console.log(val < ci[0] || val > ci[1] ? "not ok (value is not in the credible interval)" : "ok (value is in the credible interval)")

}


/*
   Another stat function

    // ...
    stat2(d,"p")


   min: 2.0086531476002376
   Stat for v: p
   min: 2.0086531476002376 mean: 10.271903813176168 max: 1941.3758492450218 stdev: 38.93330207692748

*/

// This does not work for results from Enumerate
var stat2 = function(d,v) {
    console.log("Stat for v:",v);
    var m = marginalize(d, v);
    var s = m.supp;
    var mean = listMean(s);
    var stdev = listStdev(s,mean);
    console.log("min:",_.min(s),"mean:",mean,"max:",_.max(s),"stdev:",stdev);
    console.log()    
}

/*
   Using result from Enumerate requires a different approach.

   This works for Enumerate as well as for other methods.
   It takes n samples from the distribution d[v].
*/
var stat3 = function(d,v,n) {
    var marg = marginalize(d,v)
    var s = repeat(n, function() {sample(marg)})
    var mean = listMean(s);
    var stdev = listStdev(s,mean);
    console.log("min:",_.min(s),"mean:",mean,"max:",_.max(s),"stdev:",stdev);
    console.log()

}

/*
   Pluck values (key) from an array of dicts.

   From https://stackoverflow.com/questions/25726066/equivalent-of-underscore-pluck-in-pure-javascript
*/
var pluck = function(arr,key) {
    return hakank_utils.pluck(arr,key)
}

/*
  Returns a normalized vector, i.e. where the sum is 1

  simplex([1,20]) ->  
    [ 0.047619047619047616, 0.9523809523809523 ]

  This is for use with e.g. categorical({ps:simplex([1,2,3,4,5]),vs:[....]})

*/
var simplex = function(v) {
    var s = sum(v)
    return mapN(function(i) { return v[i] / s },v.length)
}


/* 
   Draw n values from array a without replacements
   Run as
     draw_without_replacements(n,a,[])
   or
     draw_without_replacements(n,a)

   Note: This will remove all values from a that matches d.

*/
var draw_without_replacement = function(n,a,res) {
    if (arguments.length == 2) {
        // Fix since I tend to forget the last []
        return draw_without_replacement(n,a,[])
    }
    
    if (n == 0 || a.length == 0) {
        return res
    } else {
        var d = uniformDraw(a)
        var new_a = _.difference(a,[d])
        return draw_without_replacement(n-1,new_a, res.concat(d))
    }
}

/*
  Draw n values from array a without replacements
  Run as
    draw_without_replacements2(n,a,[])
  or
    draw_without_replacements2(n,a)

  Note: Compared to draw_without_replacement(), this variant does
  only remove one value. draw_without_replacement() might remove many values
  (all that matched value of pick).
  This is a little messy since there seems to be no Javascript/lodash function
  that only remove the i'th value and returns a pair of (i'th value, the rest of the array).
  Most functions remove the values from the array inline which is not what I want...
*/
var draw_without_replacement2 = function(n,a,res) {
    if (arguments.length == 2) {
        // Fix since I tend to forget the last []
        return draw_without_replacement2(n,a,[])
    }
    var len = a.length
    if (n == 0 || len == 0) {
        return res
    } else {
        var len = a.length
        // Create a temporary array with values 0..len-1
        // and pick one of these values.
        var t = _.range(len)
        var pick = randomInteger(len)
        var selected = t[pick]
        // Removed the picked value
        var new_t = _.without(t,t[pick])
        // Remove the value in a of the pick'th index
        var new_a = map(function(i) { return a[i]},new_t)
        return draw_without_replacement2(n-1,new_a, res.concat(a[selected]))
    }
}

/*
  shuffle(a)
  Returns a shuffled version of a.
  Note that this method uses Math.rand() so it's not appropriate for Enumerate (exact) 
  calculations; in those cases, use shuffle2() instead
*/
var shuffle = function(a) {
    return hakank_utils.shuffle(a)
}

/*
  shuffle2(a)
  Return a shuffled version of a.
  Note: This version uses draw_without_replacement2() which can be used with Enumerate (exact)
  calculation (at least when the size is rather small; for larger arrays it will take a 
  long time to generate all possible permutations).
*/
var shuffle2 = function(a) {
    return draw_without_replacement2(a.length,a,[])
}


/*
  Draw - with replacement - n elements from data.
*/
var resample = function(n,data) {
    return mapN(function() {return uniformDraw(data)},n)
}

/* 
  rep(n,val)
  Return an array with n occurrences of val.
*/
var rep = function(n,val) {
    return repeat(n,function() {val})
}

/*
  count(val,data)
  Return the number of occurrences of val in the array data
*/
var count = function(val,data) {
    return sum(map(function(v) {v == val ? 1 :0},data))
}

/* 
  accumulate_data(data,func)

  Returns the accumulated values of the data when processed with the function fun().
  Example:
  var a = [1,2,3,5,8,13,21,34,55]
  accumulate_data(a,function(v1,v2) {v1/v2})
  ->
  [ 0.5,
  0.6666666666666666,
  0.6,
  0.625,
  0.6153846153846154,
  0.6190476190476191,
  0.6176470588235294,
  0.6181818181818182 ]

*/
var accumulate_data = function(data, fun) {
    return mapN(function(i) { fun(data[i],data[i+1]) }, data.length-1)
}

/*
  accumulate_data1(data, fun)

  Same as accumulate_data(data, fun) but the first value is data[0].

  Example:
  var a = [1,2,3,5,8,13,21,34,55]
  accumulate1(a,function(v1,v2) {v1/v2})
  -> 
  [ 0.5,
    0.6666666666666666,
    0.6,
    0.625,
    0.6153846153846154,
    0.6190476190476191,
    0.6176470588235294,
    0.6181818181818182 ]

*/
var accumulate_data1 = function(data, fun) {
    return [data[0]].concat(mapN(function(i) { fun(data[i],data[i+1]) }, data.length-1))
}


/*
  listMedian(data) 

  Returns the median value of the data

*/
var listMedian = function(data) {
    var mid = Math.floor(data.length / 2)
    var sorted = sort(data)
    return data.length % 2 === 0 ? sorted[mid-1] + sorted[mid] / 2 : sorted[mid]
}

/*
  correlation_coefficient(a,b) 

  Returns the correlation coeffient between the two arrays a and b.
  a and b must be of the same length.
*/
var correlation_coefficient = function(a,b) {
    return hakank_utils.correlation_coefficientJS(a,b)
}

/*
  quantile(dist,q,n)

  Get the q'th quantile of a distribution dist (by n samples),

  Note that dist much be a distribution wrapped in a function() { dist(....) }

  Example: 
    What is the 0.999'th quantile for binomial(1/365,90), using 10000 samples:
    console.log(quantile(function() { return binomial(1/365,90) },0.999,10000))
    -> 3 
    
*/
var quantile = function(dist,q,n) {
    return _.first(quantiles(dist,[q],n))
}


/*
  quantiles(dist,qs,n)

  Get the qs'th quantiles of a distribution dist (using n samples),

  Note that dist much be a distribution wrapped in a function() { ... }

  Example: 
    What are the [0.90,0.95,0.99,0.999]'th quantiles for binomial(1/365,90) using 10000 samples:
    console.log(quantiles(function() { return binomial(1/1000,90)},[0.90,0.95,0.99,0.999],10000))
    ->  [ 0, 1, 1, 2 ]
*/
var quantiles = function(dist,qs,n) {
    // var sss = mapN(dist,n) // A little faster than SMC, but not as accurate
    
    var model = function() {
        var d = dist()
        return d 
    }
    var dd = Infer({method:"SMC",particles:n},model)
    // var dd = Infer({method:"MCMC",samples:n},model)
    // var dd = Infer({method:"rejection",samples:n},model)
    var sss = getSamples(dd)
    var pcts = percentile_pct(sss,qs)
    return pcts
}


// Binomial cofficient: nCk
// https://en.wikipedia.org/wiki/Binomial_coefficient
var binomialf = function(n,k) {
    return hakank_utils.binomial_coeff(n,k)
}

// Factorial function
// https://en.wikipedia.org/wiki/Factorial
var factorial = function(n) {
    return hakank_utils.factorial(n)
}

// Gamma function
// https://en.wikipedia.org/wiki/Gamma_function
var gammaf = function(n) {
    return factorial(n-1)
}

// Beta function
// https://en.wikipedia.org/wiki/Beta_function
var betaf = function(a,b) {
    gammaf(a)*gammaf(b)/gammaf(a+b)
}

/* 
  erfInv(x)
  Returns the inverse Erf function.
*/
var erfInv = function(x) {
    return hakank_utils.erfInv(x)
}


// From https://stackoverflow.com/questions/8816729/javascript-equivalent-for-inverse-normal-function-eg-excels-normsinv-or-nor
var erfcinv = function(p) {
    return hakank_utils.erfcinv(p)
}

// From https://stackoverflow.com/questions/8816729/javascript-equivalent-for-inverse-normal-function-eg-excels-normsinv-or-nor
var erfc = function(p) {
    return hakank_utils.erfc(p)
}

// From https://stackoverflow.com/questions/8816729/javascript-equivalent-for-inverse-normal-function-eg-excels-normsinv-or-nor
var erf = function(p) {
    return hakank_utils.erf(p)
}

var convert_array_to_hash = function(a,label) {
    return hakank_utils.convert_array_to_hash(a,label)
}

/*
  Harmonic number 
  https://en.wikipedia.org/wiki/Zipf%27s_law
  H,N
*/
var harmonic_number = function(n) {
    return sum(mapN(function(i) { 1/(i+1) }, n))
}

/*
  Generatlized Harmonic number
  Hs,N
*/
var harmonic_number_generalized = function(n,s) {
    return sum(mapN(function(i) { 1/Math.pow(i+1,s) }, n))
}

var zetaf = function(n) {
    return hakank_utils.zetaf(n)
}

var collect = function(a) {
    return hakank_utils.collect(a)
}

/*
  Transpose a matrix 
*/
var transpose = function(a) {
    var n = a.length
    var m = a[0].length
    return mapN(function(i) {
        return mapN(function(j) {
            return a[j][i]
        },n)
    },m)
}


/*
  Sort two lists "in parallel".
  Returns the list xs sorted together with the appropriate values in ys.
  The returned list is of the form
   [ [xs1,ys1],
     [xs2,ys2],
     ...
   ]
  
  Note: This function isn't really necessary since the following works
    var data = transpose([xs,ys])
    var sorted_sata = sort(data)
  
*/
var sort_parallel = function(xs,ys) {
    var t = _.flatten(map(function(v) {
        var d = map(function(v) {[xs[v],ys[v]]},filter(function(i) { xs[i] == v},_.range(xs.length)))
        d
    }, sort(_.uniq(xs))))
    return t 
}


/* 
  Return range of 1..n (instead of _.range()'s 0..n-1.
*/
var range1 = function(n) {
    map(function(v) { v + 1 },_.range(n))
}



// For testing
var hello2 = function(name) {
    return "hello " + name + " from WebPPL"
}
