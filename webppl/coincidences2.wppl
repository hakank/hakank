/*
  Coincidences 

  This is a port (or at least inspired) by old simulations in R
  written in 2003 (in Swedish):
  http://www.hakank.org/sims/coincidence_simulating.html
  and the Swedish blog post "Sammanträffanden - anteckningar vid läsning 
  av Diaconis och Mosteller 'Methods for Studying Coincidences'" 
  ("Coincidences - note from a reading of Diaconis and Mosteller 'Methods for Studying Coincidences'")
  http://www.hakank.org/webblogg/archives/000216.html

  (translated)
  """
  The study of coincidences is related to cognitive illusions (which is the current interest). 
  We have bad intuition regarding coincidences which the birthday problems shows: 
  It takes about 23 person for it to be a 50% probability that two persons in this group 
  shares the birthday. Surprising? A common intuition is that it require many more people .
  ...
  Here I simulate some of the most interesting sections in Diaconis' and Mosteller's paper
  'Methods for Studying Coincidences', section "7.1 General-Purpose Models: Birthday Problems" (857ff).
  """ 
  (A more detailed analysis - in Swedish - and R code is here:
   http://www.hakank.org/sims/coincidence_simulating.html
  )


  This model implements the more fancy variation where people has more than one attribute 
  that they can have in common.


  Here we show an example with 100 people with the following attributes:
  - the birthday (1..365)
  - number of theater performances during a year (1..500)
  - attending school (1..1000)

  How many pairs of people has at least one attribute in common?

 
  The theoretical values (number of persons required for 50% and 95% chance)
  according to Diaconics & Mosteller "Methods for Studying Coincidences"
  p.50 <- 1.2*sqrt(1/sum(1/num.vals))
  p.95 <- 2.5*sqrt(1/sum(1/num.vals))
 
  R code: p.50
  > 1.2*sqrt(1/sum(1/c(365,500,1000)))
  [1] 15.83929
  
  p.95
  > 2.5*sqrt(1/sum(1/c(365,500,1000)))
  [1] 32.99852


  * Running the model for 100 people (Rejection)
Marginals:
p
Marginal:
    true : 1
c
Marginal:
    26 : 0.09000000000000002
    32 : 0.09000000000000002
    23 : 0.09000000000000002
    30 : 0.07999999999999999
    27 : 0.07999999999999999
    25 : 0.07
    29 : 0.07
    24 : 0.05
    35 : 0.04000000000000001
    33 : 0.04000000000000001
    31 : 0.04000000000000001
    36 : 0.029999999999999995
    28 : 0.029999999999999995
    34 : 0.029999999999999995
    39 : 0.029999999999999995
    18 : 0.020000000000000004
    22 : 0.020000000000000004
    21 : 0.020000000000000004
    20 : 0.020000000000000004
    17 : 0.010000000000000005
    13 : 0.010000000000000005
    38 : 0.010000000000000005
    15 : 0.010000000000000005
    42 : 0.010000000000000005
    43 : 0.010000000000000005
p_50
Marginal:
    15.83928833289556 : 1
p_95
Marginal:
    32.99851736019909 : 1
expectation:
[ [ 'p', 1 ],
  [ 'c', 28.200000000000003 ],
  [ 'p_50', 15.83928833289556 ],
  [ 'p_95', 32.99851736019909 ] ]
credibleInterval c 0.93: [ 18, 39 ]

  * For 23 people the probability of a coincidence is much lower (of course):

  Marginals:
  p
  Marginal:
    true : 0.72
    false : 0.28
  c
  Marginal:
    1 : 0.36999999999999994
    0 : 0.28
    2 : 0.17
    3 : 0.12000000000000001
    4 : 0.05
    5 : 0.010000000000000005
  p_50
  Marginal:
    15.83928833289556 : 1
  p_95
  Marginal:
    32.99851736019909 : 1
  expectation:
  [ [ 'p', 0.72 ],
    [ 'c', 1.3200000000000003 ],
    [ 'p_50', 15.83928833289556 ],
    [ 'p_95', 32.99851736019909 ] ]
  credibleInterval c 0.93: [ 0, 3 ]


  * Let's also test p.50 = 16 people, i.e. where we would expect a probability 
    of at least one coincidence as 50%.

  Marginals:
  p
  Marginal:
    false : 0.5
    true : 0.49999999999999994
  c
  Marginal:
    0 : 0.5
    1 : 0.35
    2 : 0.13
    3 : 0.010000000000000005
    4 : 0.010000000000000005
  p_50
  Marginal:
    15.83928833289556 : 1
  p_95
  Marginal:
    32.99851736019909 : 1
  expectation:
  [ [ 'p', 0.49999999999999994 ],
    [ 'c', 0.68 ],
    [ 'p_50', 15.83928833289556 ],
    [ 'p_95', 32.99851736019909 ] ]
  credibleInterval c 0.93: [ 0, 2 ]

*/

// Return an array of pairs [i,j] s.t. i < j
var pairs = function(n) {
    return _.compact(_.flatten(mapN(function(i) {
        return mapN(function(j) {
            if (i < j) {
                return [i,j]
            }
        },n)
    },n)))
}


/*
  The theoretical values (number of persons required for 50% and 95% chance)
  according to Diaconics & Mosteller "Methods for Studying Coincidences"
  R code:
    p.50 <- 1.2*sqrt(1/sum(1/num.vals))
    p.95 <- 2.5*sqrt(1/sum(1/num.vals))
*/
var theoretical = function(a) {
    var t = Math.sqrt(1/sum(mapN(function(i) { return 1/a[i] },a.length)))
    return [1.2*t, 2.5*t]
}


var model = function() {
    // var num_people = 16 // 50% chance of at least one coincidence
    // var num_people = 23 
    // var num_people = 33  // 95% change of at least one coincidence
    var num_people = 100    
    var num_values_per_attribute = [365,500,1000]
    var num_attributes = num_values_per_attribute.length

    var p_theo = theoretical(num_values_per_attribute)
    var p_50 = p_theo[0]
    var p_95 = p_theo[1]
    
    var x = mem(function(i,k) {
        return randomInteger(num_values_per_attribute[k])
    })
    
    // Check all pairs (i < j) and count the coincidence.
    var c = sum(mapN(function(i) {
        return sum(mapN(function(j) {
            return i < j ? sum(mapN(function(k) {
                return x(i,k) == x(j,k) ? 1
                    : 0
            }, num_attributes))
            : 0
        }, num_people))
    },num_people))
    
    /*
    var pairs = pairs(num_people)
    var c = sum(mapN(function(d) {
            sum(mapN(function(k) {
                return x(pairs[d][0],k) == x(pairs[d][1],k)
            }, num_attributes))
    },pairs.length))
    */

    // Did we get at least one coincidence?
    var p = c > 0
    
    return {
        p:p,
        c:c,
        p_50:p_50,
        p_95:p_95
            
        
    }

}

var num_values_per_attribute = [365,500,1000]
var p_theo = theoretical(num_values_per_attribute)
console.log("Theoretical [p.50, p.95]:", p_theo)

// var d  = Infer(model)
var d  = Infer({method:"rejection",samples:100},model)
// var d  = Infer({method:"MCMC",samples:1000},model)
// var d  = Infer({method:"SMC",particles:100},model)
display(d)

exp_map(d,["p","c","p_50","p_95"],["marginals","expectation"])

console.log("credibleInterval c 0.93:", credibleInterval(getSamples(d,"c"),0.93))

