// from examples/logisticRegression.wppl

// ORIGINAL:
// var xs = [-10, -5, 2, 6, 10]
// var labels = [false, false, true, true, true]

// Let's play with the Challenger data
// From https://www.stat.ubc.ca/~bouchard/courses/stat520-sp2014-15/lecture/2015/02/27/notes-lecture3.html
// see ~/blog/logistic_regression-challenger.blog
var xs = [66,70,69,68,67,72,73,70,57,63,70,78,67,53,67,75,70,81,76,79,75,76,58]
// var labels = [1,0,1,1,1,1,1,1,0,0,0,1,1,0,1,1,1,1,1,1,0,1,0]
var labels = [true,false,true,true,true,true,true,true,false,false,false,true,true,false,true,true,true,true,true,true,false,true,false]


var model = function() {
  var m = gaussian(0, 1)
  var b = gaussian(0, 1)
  var sigma = gamma(1, 1)

  var y = function(x) {
    return gaussian(m * x + b, sigma)
  }
  var sigmoid = function(x) {
    return 1 / (1 + Math.exp(-1 * y(x)))
  }

  map2(
      function(x, label) {
          // factor(Bernoulli({p: sigmoid(x)}).score(label))
          observe(Bernoulli({p: sigmoid(x)}),label)
      },
      xs,
      labels)

  // return sigmoid(8)
    // return sigmoid(1)
    return {m:m,b:b,sigma:sigma};
}

var d = Infer({model, method: 'MCMC', kernel:"MH",samples:100000, burn:2000});
// var d = Infer(model);
// display(d);

exp_map(d,["m","b","sigma"],["expectation"]);
